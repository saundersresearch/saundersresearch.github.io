<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-11-26T09:51:18-06:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Adam Saunders Research</title><subtitle>Adam Saunders is a electrical and computer engineering PhD  student at Vanderbilt University interested conducting medical imaging research.</subtitle><author><name>Adam Saunders</name></author><entry><title type="html">Super-resolution Multi-Contrast Unbiased Eye Atlases with Deep Probabilistic Refinement</title><link href="http://localhost:4000/posts/eye-atlas/" rel="alternate" type="text/html" title="Super-resolution Multi-Contrast Unbiased Eye Atlases with Deep Probabilistic Refinement" /><published>2024-11-14T00:00:00-06:00</published><updated>2024-11-14T00:00:00-06:00</updated><id>http://localhost:4000/posts/eye-atlas</id><content type="html" xml:base="http://localhost:4000/posts/eye-atlas/"><![CDATA[<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/journal_headers/eye_atlas_render.png" alt="Eye atlas rendering" style="display:block; margin-left:auto; margin-right:auto" /> 
We created standardized reference images for the eye using low-resolution MRI.</p>

<p>Ho Hin Lee*, <strong>Adam M. Saunders</strong>*, Michael E. Kim, Samuel W. Remedios, Lucas W. Remedios, Yucheng Tang, Qi Yang, Xin Yu, Shunxing Bao, Chloe Cho, Louise A. Mawn, Tonia S. Rex, Kevin L. Schey, Blake E. Dewey, Jeffrey M. Spraggins, Jerry L. Prince, Yuankai Huo, Bennett A. Landman, Super-resolution multi-contrast unbiased eye atlases with deep probabilistic refinement, Journal of Medical Imaging, 11(6), 064004 (2024), <a href="https://doi.org/10.1117/1.JMI.11.6.064004">doi: 10.1117/1.JMI.11.6.064004</a>. *Equal contribution.</p>

<h1 id="abstract">Abstract</h1>
<blockquote>
  <p><strong>Purpose:</strong> Eye morphology varies significantly across the population, especially for the orbit and optic nerve. These variations limit the feasibility and robustness of generalizing population-wise features of eye organs to an unbiased spatial reference. <strong>Approach:</strong> To tackle these limitations, we propose a process for creating high-resolution unbiased eye atlases. First, to restore spatial details from scans with a low through-plane resolution compared with a high in-plane resolution, we apply a deep learning-based super-resolution algorithm. Then, we generate an initial unbiased reference with an iterative metric-based registration using a small portion of subject scans. We register the remaining scans to this template and refine the template using an unsupervised deep probabilistic approach that generates a more expansive deformation field to enhance the organ boundary alignment. We demonstrate this framework using magnetic resonance images across four different tissue contrasts, generating four atlases in separate spatial alignments. <strong>Results:</strong> When refining the template with sufficient subjects, we find a significant improvement using the Wilcoxon signed-rank test in the average Dice score across four labeled regions compared with a standard registration framework consisting of rigid, affine, and deformable transformations. These results highlight the effective alignment of eye organs and boundaries using our proposed process. <strong>Conclusions:</strong> By combining super-resolution preprocessing and deep probabilistic models, we address the challenge of generating an eye atlas to serve as a standardized reference across a largely variable population.</p>
</blockquote>]]></content><author><name>Adam Saunders</name></author><category term="Vanderbilt MASI Lab" /><category term="Vision" /><summary type="html"><![CDATA[We published our work on creating eye atlases from low-resolution MRI.]]></summary></entry><entry><title type="html">Comparison and Calibration of MP2RAGE Quantitative T1 Values to Multi-TI Inversion Recovery T1 Values</title><link href="http://localhost:4000/posts/quantitative-t1/" rel="alternate" type="text/html" title="Comparison and Calibration of MP2RAGE Quantitative T1 Values to Multi-TI Inversion Recovery T1 Values" /><published>2024-09-20T00:00:00-05:00</published><updated>2024-09-20T00:00:00-05:00</updated><id>http://localhost:4000/posts/quantitative-t1</id><content type="html" xml:base="http://localhost:4000/posts/quantitative-t1/"><![CDATA[<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/journal_headers/mp2rage_model.png" alt="Quantitative T1 bias correction model" style="display:block; margin-left:auto; margin-right:auto" /> 
We found a bias between two methods for mapping quantitative values of T1 from MRI, and we corrected that bias with a patch-based deep learning model.</p>

<p><strong>Adam M. Saunders</strong>, Michael E. Kim, Chenyu Gao, Lucas W. Remedios,  Aravind R. Krishnan, Kurt G. Schilling, Kristin P. O’Grady, Seth A. Smith, and Bennett A. Landman. Comparison and calibration of MP2RAGE quantitative T1 values to multi-TI inversion recovery T1 values. Submitted to <em>Magnetic Resonance Imaging</em>. <a href="https://arxiv.org/abs/2409.13145">[arXiv:2409.13145]</a></p>

<h1 id="abstract">Abstract</h1>
<blockquote>
  <p>While typical qualitative T1-weighted magnetic resonance images reflect scanner and protocol differences, quantitative T1 mapping aims to measure T1 independent of these effects. Changes in T1 in the brain reflect chemical and physical changes in brain tissue, such as the demyelination of axons in multiple sclerosis. Magnetization-prepared two rapid acquisition gradient echo (MP2RAGE) is an acquisition protocol that allows for efficient T1 mapping with a much lower scan time per slice compared to multi-TI inversion recovery (IR) protocols. We collect and register B1-corrected MP2RAGE acquisitions with an additional inversion time (MP3RAGE) alongside multi-TI selective inversion recovery acquisitions for four subjects and find a tissue-dependent bias between the derived T1 values. We train a patch-based ResNet-18 to calibrate the MP3RAGE T1 values to the multi-TI IR T1 values, incorporating the standard deviation of T1 calculated from a Monte Carlo simulation as an additional channel. Across four folds, the error between the MP2RAGE and T1 maps varies substantially (RMSE in white matter: 0.30 +/- 0.01 seconds, subcortical gray matter: 0.26 +/- 0.02 seconds, cortical gray matter: 0.36 +/- 0.02 seconds). Our network reduces the RMSE significantly (RMSE in white matter: 0.11 +/- 0.02 seconds, subcortical gray matter: 0.10 +/- 0.02 seconds, cortical gray matter: 0.17 +/- 0.03 seconds). Adding the standard deviation channel does not substantially change the RMSE. Using limited paired training data from both sequences, we can reduce the error between quantitative imaging methods and calibrate to one of the protocols with a neural network.</p>
</blockquote>]]></content><author><name>Adam Saunders</name></author><category term="Vanderbilt MASI Lab" /><category term="Preprint" /><summary type="html"><![CDATA[We found and corrected a bias in quantitative T1 methods using a patch-based deep learning model.]]></summary></entry><entry><title type="html">Deep Learning for a Healthier World: Detecting and Grading Diabetic Retinopathy</title><link href="http://localhost:4000/posts/honors-thesis/" rel="alternate" type="text/html" title="Deep Learning for a Healthier World: Detecting and Grading Diabetic Retinopathy" /><published>2023-08-31T00:00:00-05:00</published><updated>2023-08-31T00:00:00-05:00</updated><id>http://localhost:4000/posts/honors-thesis</id><content type="html" xml:base="http://localhost:4000/posts/honors-thesis/"><![CDATA[<p style="text-align: center; font-size:0.7em;"><a href="https://www.youtube.com/watch?v=J4TdP8eGEm4" style="display:block; margin-left:auto; margin-right:auto"><img src="https://img.youtube.com/vi/J4TdP8eGEm4/0.jpg" alt="Deep Learning for a Healthier World: Detecting and Grading Diabetic Retinopathy" /></a> 
<a href="https://www.youtube.com/watch?v=J4TdP8eGEm4">Deep Learning for a Healthier World: Detecting and Grading Diabetic Retinopathy</a></p>

<p>In late April 2023, I presented a talk at the first-ever Honors Thesis Signature Talks at Stander Symposium at the University of Dayton. These talks featured four undergraduate honors researchers presenting their work in a TED-style format. In my talk, <em>Deep Learning for a Healthier World: Detecting and Grading Diabetic Retinopathy</em>, I discuss my family’s experience with diabetic retinopathy, and how it inspired me to pursue medical imaging research. I explore how we can use deep learning models to learn patterns from medical images, making them a useful tool for detecting diseases like diabetic retinopathy. We can apply innovative transformations that recolor, resize, crop and transform the images to allow the deep learning model to learn to detect diseases more easily.</p>

<p>In addition, my honors thesis paper is available online as well: 
<a href="https://ecommons.udayton.edu/uhp_theses/423/">Methods for Exploiting High-Resolution Imagery for Deep Learning-Based Diabetic Retinopathy Detection and Grading</a></p>

<p><strong>Abstract</strong></p>
<blockquote>
  <p>Diabetic retinopathy is a disease that affects the eyes of people with diabetes, and it can cause blindness. To diagnose diabetic retinopathy, ophthalmologists image the back surface of the inside of the eye, a process referred to as fundus photography. Ophthalmologists must then diagnose and grade the severity of diabetic retinopathy by analyzing details in the image, which can be difficult and time-consuming. Alternatively, due to the availability of labeled datasets containing fundus images with diabetic retinopathy, AI methods like deep learning can provide automated detection and grading algorithms. We show that the resolution of an image has a large effect on the accuracy of grading algorithms. So, we study several techniques to increase the accuracy of the algorithm by taking advantage of higher-resolution data, including using a region of interest as the input and applying an image transformation to make the circular fundus image square. While none of our proposed methods result in an increase in performance for grading diabetic retinopathy, the circle to square transformation results in an increase in accuracy and AUC for detection of diabetic retinopathy. This work provides a useful starting point for future research aimed at increasing the resolution content in a fundus image.</p>
</blockquote>]]></content><author><name>Adam Saunders</name></author><category term="University of Dayton" /><summary type="html"><![CDATA[I presented a TED-style talk highlighting the aims of my honors thesis research into diabetic retinopathy imaging and deep learning.]]></summary></entry><entry><title type="html">Graduation from University of Dayton</title><link href="http://localhost:4000/posts/ud-graduation/" rel="alternate" type="text/html" title="Graduation from University of Dayton" /><published>2023-05-08T00:00:00-05:00</published><updated>2023-05-08T00:00:00-05:00</updated><id>http://localhost:4000/posts/UD-graduation</id><content type="html" xml:base="http://localhost:4000/posts/ud-graduation/"><![CDATA[<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/graduation.jpg" alt="Graduation photo" style="display:block; margin-left:auto; margin-right:auto" /> 
I celebrated my graduation from the University of Dayton</p>

<p>I’m proud to announce I have officially graduated from the University of Dayton! I have graduated with a Bachelor of Electrical Engineering with a minor in Mathematics. It’s been a great few years, and I’m excited for what’s next.</p>

<p>I graduated <i>summa cum laude</i>. In addition, I was the recipient of the Thomas R. Armstrong Award of Excellence for Outstanding Electrical Engineering Achievement. Along with my twin brother Nick, I also received the Department of Music’s Senior Award for Outstanding Collaborative Pianist. I was very honored to receive these awards, and I think they highlight one of the main reasons I first chose to attend UD - I worked hard to study engineering while also continuing to include music in my life. I hope to be able to continue incorporating music into my life, especially as a piano accompanist.</p>

<p>The next step for me is moving to Nashville to begin a PhD program at Vanderbilt University! I’m super excited to continue performing medical imaging research. I’m overwhelmed with gratitude for everyone who has helped get me to this point. The journey to becoming an electrical engineer has not been easy, but it has certainly been worth it!</p>]]></content><author><name>Adam Saunders</name></author><category term="University of Dayton" /><summary type="html"><![CDATA[I graduated summa cum laude from the University of Dayton with a Bachelor of Electrical Engineering.]]></summary></entry><entry><title type="html">I Accepted a PhD Offer at Vanderbilt!</title><link href="http://localhost:4000/posts/phd-acceptance/" rel="alternate" type="text/html" title="I Accepted a PhD Offer at Vanderbilt!" /><published>2023-04-06T00:00:00-05:00</published><updated>2023-04-06T00:00:00-05:00</updated><id>http://localhost:4000/posts/PhD-acceptance</id><content type="html" xml:base="http://localhost:4000/posts/phd-acceptance/"><![CDATA[<p>I’m excited to share that I have accepted a PhD offer from Vanderbilt University! I will be joining the <a href="https://my.vanderbilt.edu/masi/">Medical-image Analysis and Statistical Interpretation (MASI) Lab</a> under Dr. Bennett Landman.</p>

<p>This lab is a part of <a href="https://www.vanderbilt.edu/vise/">Vanderbilt Institute for Surgery and Engineering (VISE)</a>, an exciting, cross-disciplinary set of labs that works in the intersection between medicine, computer science, engineering, and more. So, I’ll officially be a part of the newly-formed Department of Electrical and Computer Engineering, and I will also have the chance to work alongside people across disciplinary boundaries.</p>

<p>I’m ready to move to Nashville and continuing pursuing my goal of earning a PhD!</p>

<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/centennial_park.jpg" alt="Centennial Park" style="display:block; margin-left:auto; margin-right:auto" /> 
I visited Centennial Park in Nashville while on a visit to Vanderbilt</p>]]></content><author><name>Adam Saunders</name></author><category term="Vanderbilt MASI Lab" /><summary type="html"><![CDATA[I accepted a PhD offer from Vanderbilt University at the MASI Lab under Dr. Bennett Landman.]]></summary></entry><entry><title type="html">My First Time at SPIE Medical Imaging</title><link href="http://localhost:4000/posts/spie-medical-imaging-2023/" rel="alternate" type="text/html" title="My First Time at SPIE Medical Imaging" /><published>2023-03-08T00:00:00-06:00</published><updated>2023-03-08T00:00:00-06:00</updated><id>http://localhost:4000/posts/SPIE-2023</id><content type="html" xml:base="http://localhost:4000/posts/spie-medical-imaging-2023/"><![CDATA[<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/spie_portrait.jpg" alt="Adam Saunders at SPIE Medical Imaging" style="display:block; margin-left:auto; margin-right:auto" /> 
I presented at SPIE Medical Imaging for the first time</p>

<p>I recently got the chance to travel to San Diego to present research I performed at Oak Ridge National Laboratory at the 2023 SPIE Medical Imaging conference. This was the first professional conference I’ve attended, and getting the chance to go as an undergraduate was a great experience. I was lucky enough to receive a student travel grant from SPIE to attend.</p>

<p>I was definitely a bit nervous at first to be attending the conference by myself. In fact, I had never traveled alone. However, everyone at the conference was very friendly. I got to meet lots of people from all over the world - Italy, the UK, the Netherlands, and all over the US as well! It was so refreshing to meet people working in medical imaging, especially other students. A highlight for me was talking to students from the <a href="https://my.vanderbilt.edu/masi/">MASI Lab</a> at Vanderbilt University, as I’ve applied to join this lab next year as a PhD student.</p>

<p>As someone just starting out in medical imaging, it was very nice to see all of the interesting research going on. The keynote speakers were really fantastic. I particularly enjoyed hearing <a href="https://www.zacharylipton.com/">Zachary Lipton</a> from Carnegie Mellon talk about how the attention mechanism is not a great interpretability measure for deep learning models. If I’m summarizing his talk correctly, his team has found that we can have vastly different attention weights and still get the same accuracy. This result was a bit sombering for people like me who have advertized the attention mechanism as a way of boosting interpretability for image classification. Overall, the talks were very thought-provoking and introduced me to a lot of new ideas.</p>

<p>I got to present the work I performed at Oak Ridge National Laboratory titled “A comparison of histopathology imaging comprehension algorithms based on multiple instance learning.” In this work, we used a supercomputer to compare several multiple instance learning algorithms for whole-slide image classification of cancer datasets. We found that algorithms using the attention mechanism all performed better than those without. It was great to be able to present my work to people who really understood the problem. I had some great conversations with people about what this work meant and how it compared with other researchers’ findings.</p>

<p>I also got to explore San Diego a bit. I went to Mission Beach with a group of students and got to see the Pacific Ocean for the first time! It was cold and rainy - very unseasonable weather for San Diego. I also got to go to Old Town and do some shopping and eating, which was nice.</p>

<p>SPIE Medical Imaging was a great conference, and they were a particularly warm and welcoming group for a first-timer. I hope I’m able to return sometime in the future!</p>]]></content><author><name>Adam Saunders</name></author><category term="Oak Ridge National Laboratory" /><category term="SPIE Medical Imaging" /><summary type="html"><![CDATA[I attended SPIE Medical Imaging for the first time and presented research I performed last summer on comparing whole-slide image classification algorithms.]]></summary></entry><entry><title type="html">Using Supercomputers to Detect Cancer: My Summer at Oak Ridge National Lab</title><link href="http://localhost:4000/posts/ornl-internship/" rel="alternate" type="text/html" title="Using Supercomputers to Detect Cancer: My Summer at Oak Ridge National Lab" /><published>2022-08-14T00:00:00-05:00</published><updated>2022-08-14T00:00:00-05:00</updated><id>http://localhost:4000/posts/ORNL-internship</id><content type="html" xml:base="http://localhost:4000/posts/ornl-internship/"><![CDATA[<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/frontier_selfie_square.jpg" alt="Adam Saunders with Frontier" style="display:block; margin-left:auto; margin-right:auto" /> 
I visited Frontier, the world’s fastest supercomputer, as a part of the SULI program this summer</p>

<p>How many people can say they got the chance to use one of the fastest computers in the world to detect cancer? I was extremely lucky to be able to do just that this summer at Oak Ridge National Laboratory in Tennessee. I participated in the Department of Energy’s Science Undergraduate Laboratory Internship (SULI) program, and the experience was incredible.</p>

<p>This past June, I packed up my things and headed down to Knoxville, Tennessee, where I would spend the next few months performing research at nearby Oak Ridge National Laboratory (ORNL). ORNL is one of the Department of Energy’s largest national labs, with nearly 6,000 staff that span a wide variety of research interests from nuclear physics to soil science. ORNL has a fascinating history as well — it was one of the main research sites that powered the Manhattan Project.</p>

<p>The SULI program allows students to spend 10 weeks performing research alongside a mentor at the lab. I worked under Dr. Hong-Jun Yoon to compare machine learning algorithms for analyzing whole-slide images, which are large digital scans of tissue samples. I used Summit, the second-fastest supercomputer in the United States and fourth-fastest in the world, to train and test machine learning models on a massive scale. We successfully detected and subtyped cancers from several datasets.</p>

<p>Along with gaining technical skills in medical image processing and high-performance computing, I also learned how to communicate my results to the wider scientific community. We submitted a manuscript to the 2023 SPIE Medical Imaging conference, and it hopefully will be my first publication. Also, at the ORNL Summer Intern Symposium, my poster won Best Poster in the Computing and Computational Sciences Directorate! You can see my poster and read more about the research I did this summer <a href="/research/">here</a>.</p>

<p>Outside of my research, I toured several of the unique facilities on campus. I visited X-10, the world’s first continuously operating nuclear reactor. Seeing the name “Oppenheimer” on one of the nameplates was sombering — I was in the former offices of some of the world’s greatest physicists! I also got to see Frontier, the fastest (and greenest) supercomputer in the world!</p>

<p style="text-align: center; font-size:0.7em;"><img src="/assets/images/graphite_reactor_square.jpg" alt="X-10 Graphite Reactor" style="display:block; margin-left:auto; margin-right:auto" /> 
The graphite reactor at ORNL is the world’s first continuously operating nuclear reactor</p>

<p>Getting to spend the summer at ORNL was invigorating, and I developed a passion for medical image processing that I want to pursue further. I consider myself very fortunate for being able to participate in the SULI program, and I hope that I will be able to return to ORNL sometime in the future!</p>]]></content><author><name>Adam Saunders</name></author><category term="Oak Ridge National Laboratory" /><summary type="html"><![CDATA[I spent the summer at Oak Ridge National Lab, performing exciting research into designing machine learning algorithms for cancer detection from whole-slide images.]]></summary></entry></feed>